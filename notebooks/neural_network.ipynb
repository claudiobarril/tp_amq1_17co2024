{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bc00dc19f967113b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T13:55:23.388797Z",
     "start_time": "2024-10-18T13:55:22.069882Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ruta añadida al sys.path: c:\\Users\\Iñaki\\Desktop\\Master inteligencia artificial\\Machine Learning 1\\trabajo final\\tp_amq1_17co2024\\src\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from sklearn.metrics import mean_absolute_error, root_mean_squared_error, \\\n",
    "    mean_absolute_percentage_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import os\n",
    "src_path = os.path.abspath(os.path.join(os.getcwd(), '..', 'src'))\n",
    "sys.path.append(src_path)\n",
    "\n",
    "# Verificar si la ruta ha sido añadida correctamente\n",
    "print(f\"Ruta añadida al sys.path: {src_path}\")\n",
    "\n",
    "# Ahora puedes intentar importar los módulos\n",
    "from models.pipeline import CarsPipeline\n",
    "from models.used_car_quote_nn import UsedCarQuoteNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T13:55:24.171523Z",
     "start_time": "2024-10-18T13:55:23.389540Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Iñaki\\Desktop\\Master inteligencia artificial\\Machine Learning 1\\trabajo final\\.venv\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:242: UserWarning: Found unknown categories in columns [3] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('../datasets/Car details v3.csv')\n",
    "\n",
    "data[\"selling_price_log\"] = np.log1p(data[\"selling_price\"])\n",
    "\n",
    "X = data.drop(columns=['selling_price', 'selling_price_log'])\n",
    "y = data['selling_price']\n",
    "y_log = data['selling_price_log']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "X_train_log, X_test_log, y_train_log, y_test_log = train_test_split(X, y_log, test_size=0.3, random_state=42)\n",
    "final_pipeline = CarsPipeline()\n",
    "\n",
    "X_train_processed = final_pipeline.fit_transform_df(X_train)\n",
    "X_test_processed = final_pipeline.transform_df(X_test)\n",
    "\n",
    "X_train_tensor = torch.tensor(X_train_processed.to_numpy(), dtype=torch.float32)\n",
    "X_test_tensor = torch.tensor(X_test_processed.to_numpy(), dtype=torch.float32)\n",
    "y_train_tensor_log = torch.tensor(y_train_log.to_numpy(), dtype=torch.float32).view(-1, 1)\n",
    "y_test_tensor_log = torch.tensor(y_test_log.to_numpy(), dtype=torch.float32).view(-1, 1)\n",
    "\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor_log)\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor_log)\n",
    "\n",
    "batch_size = 64\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "eceb4703",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImprovedCarQuoteNN(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(ImprovedCarQuoteNN, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(input_dim, 128),  # Más neuronas\n",
    "            nn.ReLU(),  # Activación no lineal\n",
    "            nn.Dropout(0.3),  # Dropout para evitar sobreajuste\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 1)  # Regresión a un solo valor\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "# Redefinir el modelo con la nueva arquitectura\n",
    "input_dim = X_train_processed.shape[1]\n",
    "model = ImprovedCarQuoteNN(input_dim)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "12c01a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.HuberLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0d757303",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)  # Probar con Adam y una tasa de aprendizaje más baja\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b266b44c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Iñaki\\Desktop\\Master inteligencia artificial\\Machine Learning 1\\trabajo final\\.venv\\Lib\\site-packages\\torch\\optim\\lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Validation Loss: 0.8356\n",
      "Epoch 2, Validation Loss: 0.2899\n",
      "Epoch 3, Validation Loss: 0.2753\n",
      "Epoch 4, Validation Loss: 0.1492\n",
      "Epoch 5, Validation Loss: 0.1962\n",
      "Epoch 6, Validation Loss: 0.1155\n",
      "Epoch 7, Validation Loss: 0.1022\n",
      "Epoch 8, Validation Loss: 0.0832\n",
      "Epoch 9, Validation Loss: 0.1270\n",
      "Epoch 10, Validation Loss: 0.0960\n",
      "Epoch 11, Validation Loss: 0.1618\n",
      "Epoch 12, Validation Loss: 0.1533\n",
      "Epoch 13, Validation Loss: 0.0919\n",
      "Epoch 14, Validation Loss: 0.1439\n",
      "Epoch 15, Validation Loss: 0.0792\n",
      "Epoch 16, Validation Loss: 0.1208\n",
      "Epoch 17, Validation Loss: 0.0440\n",
      "Epoch 18, Validation Loss: 0.0538\n",
      "Epoch 19, Validation Loss: 0.0414\n",
      "Epoch 20, Validation Loss: 0.0411\n",
      "Epoch 21, Validation Loss: 0.0631\n",
      "Epoch 22, Validation Loss: 0.0870\n",
      "Epoch 23, Validation Loss: 0.0361\n",
      "Epoch 24, Validation Loss: 0.0640\n",
      "Epoch 25, Validation Loss: 0.0353\n",
      "Epoch 26, Validation Loss: 0.0679\n",
      "Epoch 27, Validation Loss: 0.0365\n",
      "Epoch 28, Validation Loss: 0.0406\n",
      "Epoch 29, Validation Loss: 0.0324\n",
      "Epoch 30, Validation Loss: 0.0718\n",
      "Epoch 31, Validation Loss: 0.0388\n",
      "Epoch 32, Validation Loss: 0.0297\n",
      "Epoch 33, Validation Loss: 0.0523\n",
      "Epoch 34, Validation Loss: 0.0303\n",
      "Epoch 35, Validation Loss: 0.0299\n",
      "Epoch 36, Validation Loss: 0.0312\n",
      "Epoch 37, Validation Loss: 0.0320\n",
      "Epoch 38, Validation Loss: 0.0286\n",
      "Epoch 39, Validation Loss: 0.0298\n",
      "Epoch 40, Validation Loss: 0.0341\n",
      "Epoch 41, Validation Loss: 0.0338\n",
      "Epoch 42, Validation Loss: 0.0402\n",
      "Epoch 43, Validation Loss: 0.0287\n",
      "Epoch 44, Validation Loss: 0.0294\n",
      "Epoch 45, Validation Loss: 0.0273\n",
      "Epoch 46, Validation Loss: 0.0278\n",
      "Epoch 47, Validation Loss: 0.0281\n",
      "Epoch 48, Validation Loss: 0.0327\n",
      "Epoch 49, Validation Loss: 0.0271\n",
      "Epoch 50, Validation Loss: 0.0276\n",
      "Epoch 51, Validation Loss: 0.0266\n",
      "Epoch 52, Validation Loss: 0.0336\n",
      "Epoch 53, Validation Loss: 0.0296\n",
      "Epoch 54, Validation Loss: 0.0288\n",
      "Epoch 55, Validation Loss: 0.0260\n",
      "Epoch 56, Validation Loss: 0.0263\n",
      "Epoch 57, Validation Loss: 0.0321\n",
      "Epoch 58, Validation Loss: 0.0273\n",
      "Epoch 59, Validation Loss: 0.0272\n",
      "Epoch 60, Validation Loss: 0.0264\n",
      "Epoch 61, Validation Loss: 0.0305\n",
      "Epoch 62, Validation Loss: 0.0271\n",
      "Epoch 63, Validation Loss: 0.0279\n",
      "Epoch 64, Validation Loss: 0.0257\n",
      "Epoch 65, Validation Loss: 0.0264\n",
      "Epoch 66, Validation Loss: 0.0253\n",
      "Epoch 67, Validation Loss: 0.0260\n",
      "Epoch 68, Validation Loss: 0.0270\n",
      "Epoch 69, Validation Loss: 0.0288\n",
      "Epoch 70, Validation Loss: 0.0251\n",
      "Epoch 71, Validation Loss: 0.0249\n",
      "Epoch 72, Validation Loss: 0.0248\n",
      "Epoch 73, Validation Loss: 0.0246\n",
      "Epoch 74, Validation Loss: 0.0261\n",
      "Epoch 75, Validation Loss: 0.0256\n",
      "Epoch 76, Validation Loss: 0.0288\n",
      "Epoch 77, Validation Loss: 0.0295\n",
      "Epoch 78, Validation Loss: 0.0259\n",
      "Epoch 79, Validation Loss: 0.0311\n",
      "Epoch 80, Validation Loss: 0.0248\n",
      "Epoch 81, Validation Loss: 0.0246\n",
      "Epoch 82, Validation Loss: 0.0249\n",
      "Epoch 83, Validation Loss: 0.0235\n",
      "Epoch 84, Validation Loss: 0.0243\n",
      "Epoch 85, Validation Loss: 0.0249\n",
      "Epoch 86, Validation Loss: 0.0240\n",
      "Epoch 87, Validation Loss: 0.0251\n",
      "Epoch 88, Validation Loss: 0.0240\n",
      "Epoch 89, Validation Loss: 0.0241\n",
      "Epoch 90, Validation Loss: 0.0245\n",
      "Epoch 91, Validation Loss: 0.0258\n",
      "Epoch 92, Validation Loss: 0.0251\n",
      "Epoch 93, Validation Loss: 0.0241\n",
      "Epoch 94, Validation Loss: 0.0237\n",
      "Epoch 95, Validation Loss: 0.0246\n",
      "Epoch 96, Validation Loss: 0.0235\n",
      "Epoch 97, Validation Loss: 0.0237\n",
      "Epoch 98, Validation Loss: 0.0234\n",
      "Epoch 99, Validation Loss: 0.0234\n",
      "Epoch 100, Validation Loss: 0.0233\n"
     ]
    }
   ],
   "source": [
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "# Early stopping puede ser implementado manualmente o usando ReduceLROnPlateau\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=10, verbose=True)\n",
    "\n",
    "n_epochs = 100\n",
    "best_loss = float('inf')\n",
    "patience, trials = 20, 0\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for X_batch, y_batch in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        y_pred = model(X_batch)\n",
    "        loss = loss_fn(y_pred, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    # Validación\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        val_loss = 0.0\n",
    "        for X_val, y_val in test_loader:\n",
    "            y_val_pred = model(X_val)\n",
    "            val_loss += loss_fn(y_val_pred, y_val).item()\n",
    "\n",
    "    val_loss /= len(test_loader)\n",
    "    print(f\"Epoch {epoch+1}, Validation Loss: {val_loss:.4f}\")\n",
    "    \n",
    "    # Early stopping\n",
    "    scheduler.step(val_loss)\n",
    "    if val_loss < best_loss:\n",
    "        best_loss = val_loss\n",
    "        trials = 0\n",
    "    else:\n",
    "        trials += 1\n",
    "        if trials >= patience:\n",
    "            print(\"Early stopping triggered\")\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b5dfa3a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "\n",
    "y_pred_log_list = []\n",
    "y_test_log_list = []\n",
    "\n",
    "# Desactivar el gradiente para la evaluación\n",
    "with torch.no_grad():\n",
    "    for X_batch, y_batch in test_loader:\n",
    "        y_pred = model(X_batch)\n",
    "        y_pred_log_list.append(y_pred.numpy())\n",
    "        y_test_log_list.append(y_batch.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "30ac3b56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name: NN\n",
      "MAE_log: 0.15879565477371216\n",
      "MAE: 88356.421875\n",
      "RMSE: 193866.421875\n",
      "MAPE: 0.16696685552597046\n",
      "R2: 0.9454\n"
     ]
    }
   ],
   "source": [
    "# Convertir a arrays numpy\n",
    "y_pred_log_np = np.vstack(y_pred_log_list)\n",
    "y_test_log_np = np.vstack(y_test_log_list)\n",
    "\n",
    "# Revertir la transformación logarítmica para obtener los valores originales\n",
    "y_pred_np = np.expm1(y_pred_log_np)\n",
    "y_test_np = np.expm1(y_test_log_np)\n",
    "\n",
    "# Definir función para RMSE\n",
    "def root_mean_squared_error(y_true, y_pred):\n",
    "    return np.sqrt(np.mean((y_true - y_pred) ** 2))\n",
    "\n",
    "# Calcular métricas\n",
    "metrics_nn = {\n",
    "    \"name\": \"NN\",\n",
    "    \"MAE_log\": mean_absolute_error(y_test_log_np, y_pred_log_np),  # MAE en escala log\n",
    "    \"MAE\": mean_absolute_error(y_test_np, y_pred_np),  # MAE en escala original\n",
    "    \"RMSE\": root_mean_squared_error(y_test_np, y_pred_np),\n",
    "    \"MAPE\": mean_absolute_percentage_error(y_test_np, y_pred_np),\n",
    "    \"R2\": r2_score(y_test_np, y_pred_np)\n",
    "}\n",
    "\n",
    "# Imprimir las métricas\n",
    "for metric, value in metrics_nn.items():\n",
    "    if isinstance(value, (int, float)):  # Solo formatear si es un número\n",
    "        print(f\"{metric}: {value:.4f}\")\n",
    "    else:\n",
    "        print(f\"{metric}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "cc5a1c4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[132235.58],\n",
       "       [394876.4 ],\n",
       "       [623562.25],\n",
       "       ...,\n",
       "       [583029.25],\n",
       "       [328244.2 ],\n",
       "       [390925.6 ]], dtype=float32)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d14154ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1971    198000\n",
       "4664    500000\n",
       "5448    425000\n",
       "3333    150000\n",
       "2316    525000\n",
       "         ...  \n",
       "462     600000\n",
       "1956    400000\n",
       "3782    500000\n",
       "799     400000\n",
       "2402    425000\n",
       "Name: selling_price, Length: 2439, dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d2e10b76d51ce9c2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T13:55:24.954648Z",
     "start_time": "2024-10-18T13:55:24.173172Z"
    }
   },
   "outputs": [],
   "source": [
    "model = UsedCarQuoteNN(X_train_processed.shape[1])\n",
    "\n",
    "criterion = torch.nn.L1Loss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "926c4fae2f523a91",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T14:48:02.312446Z",
     "start_time": "2024-10-18T14:47:17.720238Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_model_batch(model, train_loader, X_val, y_val, epochs=100):\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        for X_batch, y_batch in train_loader:\n",
    "            y_pred_train = model(X_batch)\n",
    "            loss = criterion(y_pred_train, y_batch)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "        # TODO: add validation batch\n",
    "        # model.eval()\n",
    "        # with torch.no_grad():\n",
    "        #     y_pred_val = model(X_val)\n",
    "        #     criterion(y_pred_val, y_val).item()\n",
    "\n",
    "\n",
    "train_model_batch(model, train_loader, X_test_tensor, y_test_tensor_log, epochs=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d0630e62998854ef",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T14:21:57.820183Z",
     "start_time": "2024-10-18T14:21:57.731178Z"
    }
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input contains infinity or a value too large for dtype('float32').",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 38\u001b[0m\n\u001b[1;32m     32\u001b[0m y_test_np \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mexpm1(y_test_log_np)\n\u001b[1;32m     34\u001b[0m \u001b[38;5;66;03m# Calcular las métricas\u001b[39;00m\n\u001b[1;32m     35\u001b[0m metrics_nn \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     36\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNN\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     37\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMAE_training\u001b[39m\u001b[38;5;124m\"\u001b[39m: mean_absolute_error(y_test_log_np, y_pred_log_np),  \u001b[38;5;66;03m# MAE en escala logarítmica\u001b[39;00m\n\u001b[0;32m---> 38\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMAE\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[43mmean_absolute_error\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_test_np\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred_np\u001b[49m\u001b[43m)\u001b[49m,  \u001b[38;5;66;03m# MAE en escala original\u001b[39;00m\n\u001b[1;32m     39\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRMSE\u001b[39m\u001b[38;5;124m\"\u001b[39m: root_mean_squared_error(y_test_np, y_pred_np),  \u001b[38;5;66;03m# RMSE en escala original\u001b[39;00m\n\u001b[1;32m     40\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMAPE\u001b[39m\u001b[38;5;124m\"\u001b[39m: mean_absolute_percentage_error(y_test_np, y_pred_np),  \u001b[38;5;66;03m# MAPE en escala original\u001b[39;00m\n\u001b[1;32m     41\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mR2\u001b[39m\u001b[38;5;124m\"\u001b[39m: r2_score(y_test_np, y_pred_np)  \u001b[38;5;66;03m# R2 en escala original\u001b[39;00m\n\u001b[1;32m     42\u001b[0m }\n\u001b[1;32m     44\u001b[0m \u001b[38;5;66;03m# Mostrar las métricas calculadas\u001b[39;00m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28mprint\u001b[39m(metrics_nn)\n",
      "File \u001b[0;32m~/Learning/Posgrado/venv/lib/python3.12/site-packages/sklearn/utils/_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    211\u001b[0m         )\n\u001b[1;32m    212\u001b[0m     ):\n\u001b[0;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[1;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[1;32m    223\u001b[0m     )\n",
      "File \u001b[0;32m~/Learning/Posgrado/venv/lib/python3.12/site-packages/sklearn/metrics/_regression.py:216\u001b[0m, in \u001b[0;36mmean_absolute_error\u001b[0;34m(y_true, y_pred, sample_weight, multioutput)\u001b[0m\n\u001b[1;32m    152\u001b[0m \u001b[38;5;129m@validate_params\u001b[39m(\n\u001b[1;32m    153\u001b[0m     {\n\u001b[1;32m    154\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_true\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marray-like\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    162\u001b[0m     y_true, y_pred, \u001b[38;5;241m*\u001b[39m, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, multioutput\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muniform_average\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    163\u001b[0m ):\n\u001b[1;32m    164\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Mean absolute error regression loss.\u001b[39;00m\n\u001b[1;32m    165\u001b[0m \n\u001b[1;32m    166\u001b[0m \u001b[38;5;124;03m    Read more in the :ref:`User Guide <mean_absolute_error>`.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;124;03m    0.85...\u001b[39;00m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 216\u001b[0m     y_type, y_true, y_pred, multioutput \u001b[38;5;241m=\u001b[39m \u001b[43m_check_reg_targets\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    217\u001b[0m \u001b[43m        \u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmultioutput\u001b[49m\n\u001b[1;32m    218\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    219\u001b[0m     check_consistent_length(y_true, y_pred, sample_weight)\n\u001b[1;32m    220\u001b[0m     output_errors \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39maverage(np\u001b[38;5;241m.\u001b[39mabs(y_pred \u001b[38;5;241m-\u001b[39m y_true), weights\u001b[38;5;241m=\u001b[39msample_weight, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m~/Learning/Posgrado/venv/lib/python3.12/site-packages/sklearn/metrics/_regression.py:113\u001b[0m, in \u001b[0;36m_check_reg_targets\u001b[0;34m(y_true, y_pred, multioutput, dtype, xp)\u001b[0m\n\u001b[1;32m    111\u001b[0m check_consistent_length(y_true, y_pred)\n\u001b[1;32m    112\u001b[0m y_true \u001b[38;5;241m=\u001b[39m check_array(y_true, ensure_2d\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[0;32m--> 113\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mensure_2d\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y_true\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    116\u001b[0m     y_true \u001b[38;5;241m=\u001b[39m xp\u001b[38;5;241m.\u001b[39mreshape(y_true, (\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m))\n",
      "File \u001b[0;32m~/Learning/Posgrado/venv/lib/python3.12/site-packages/sklearn/utils/validation.py:1064\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m   1058\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1059\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound array with dim \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m expected <= 2.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1060\u001b[0m         \u001b[38;5;241m%\u001b[39m (array\u001b[38;5;241m.\u001b[39mndim, estimator_name)\n\u001b[1;32m   1061\u001b[0m     )\n\u001b[1;32m   1063\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m force_all_finite:\n\u001b[0;32m-> 1064\u001b[0m     \u001b[43m_assert_all_finite\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1065\u001b[0m \u001b[43m        \u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1066\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1067\u001b[0m \u001b[43m        \u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1068\u001b[0m \u001b[43m        \u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_all_finite\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mallow-nan\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1069\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1071\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m copy:\n\u001b[1;32m   1072\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_numpy_namespace(xp):\n\u001b[1;32m   1073\u001b[0m         \u001b[38;5;66;03m# only make a copy if `array` and `array_orig` may share memory`\u001b[39;00m\n",
      "File \u001b[0;32m~/Learning/Posgrado/venv/lib/python3.12/site-packages/sklearn/utils/validation.py:123\u001b[0m, in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m first_pass_isfinite:\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m--> 123\u001b[0m \u001b[43m_assert_all_finite_element_wise\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    124\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    125\u001b[0m \u001b[43m    \u001b[49m\u001b[43mxp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mxp\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    126\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_nan\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    127\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmsg_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmsg_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    128\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    129\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    130\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Learning/Posgrado/venv/lib/python3.12/site-packages/sklearn/utils/validation.py:172\u001b[0m, in \u001b[0;36m_assert_all_finite_element_wise\u001b[0;34m(X, xp, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[1;32m    155\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m estimator_name \u001b[38;5;129;01mand\u001b[39;00m input_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m has_nan_error:\n\u001b[1;32m    156\u001b[0m     \u001b[38;5;66;03m# Improve the error message on how to handle missing values in\u001b[39;00m\n\u001b[1;32m    157\u001b[0m     \u001b[38;5;66;03m# scikit-learn.\u001b[39;00m\n\u001b[1;32m    158\u001b[0m     msg_err \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    159\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not accept missing values\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    160\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m encoded as NaN natively. For supervised learning, you might want\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    170\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m#estimators-that-handle-nan-values\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    171\u001b[0m     )\n\u001b[0;32m--> 172\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg_err)\n",
      "\u001b[0;31mValueError\u001b[0m: Input contains infinity or a value too large for dtype('float32')."
     ]
    }
   ],
   "source": [
    "\n",
    "y_pred_list = []\n",
    "y_pred_list_log = []\n",
    "y_test_list_log = []\n",
    "\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for X_batch, y_batch in test_loader:\n",
    "        y_test_pred_log = model(X_batch)\n",
    "\n",
    "        y_test_pred = torch.expm1(y_test_pred_log)\n",
    "\n",
    "        y_pred_list.append(y_test_pred)  \n",
    "        y_pred_list_log.append(y_test_pred_log)\n",
    "        y_test_list_log.append(y_batch)\n",
    "\n",
    "y_pred_tensor = torch.cat(y_pred_list).squeeze()\n",
    "y_pred_log_tensor = torch.cat(y_pred_list_log).squeeze()\n",
    "y_test_log_tensor = torch.cat(y_test_list_log).squeeze()\n",
    "\n",
    "y_pred_np = y_pred_tensor.numpy()\n",
    "y_pred_log_np = y_pred_log_tensor.numpy()\n",
    "y_test_log_np = y_test_log_tensor.numpy()\n",
    "\n",
    "y_test_np = np.expm1(y_test_log_np)\n",
    "\n",
    "metrics_nn = {\n",
    "    \"name\": \"NN\",\n",
    "    \"MAE_training\": mean_absolute_error(y_test_log_np, y_pred_log_np),\n",
    "    \"MAE\": mean_absolute_error(y_test_np, y_pred_np),\n",
    "    \"RMSE\": root_mean_squared_error(y_test_np, y_pred_np),\n",
    "    \"MAPE\": mean_absolute_percentage_error(y_test_np, y_pred_np),\n",
    "    \"R2\": r2_score(y_test_np, y_pred_np)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3c075f577a8edba",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(metrics_nn)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
