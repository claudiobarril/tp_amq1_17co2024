{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T03:45:55.250346Z",
     "start_time": "2024-10-18T03:45:55.246551Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from sklearn.metrics import accuracy_score, mean_absolute_error, root_mean_squared_error, \\\n",
    "    mean_absolute_percentage_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "from src.models.used_car_quote_nn import UsedCarQuoteNN\n",
    "\n",
    "sys.path.append('../src')\n",
    "from src.models.pipeline import CarsPipeline"
   ],
   "id": "bc00dc19f967113b",
   "outputs": [],
   "execution_count": 37
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-10-18T03:13:14.114107Z",
     "start_time": "2024-10-18T03:13:12.413273Z"
    }
   },
   "source": [
    "data = pd.read_csv('../datasets/Car details v3.csv')\n",
    "\n",
    "data[\"selling_price_log\"] = np.log1p(data[\"selling_price\"])\n",
    "\n",
    "X = data.drop(columns=['selling_price', 'selling_price_log'])\n",
    "y = data['selling_price']\n",
    "y_log = data['selling_price_log']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "X_train_log, X_test_log, y_train_log, y_test_log = train_test_split(X, y_log, test_size=0.3, random_state=42)\n",
    "final_pipeline = CarsPipeline()\n",
    "\n",
    "X_train_processed = final_pipeline.fit_transform_df(X_train)\n",
    "X_test_processed = final_pipeline.transform_df(X_test)\n",
    "\n",
    "X_train_tensor = torch.tensor(X_train_processed.to_numpy(), dtype=torch.float32)\n",
    "X_test_tensor = torch.tensor(X_test_processed.to_numpy(), dtype=torch.float32)\n",
    "y_train_tensor_log = torch.tensor(y_train_log.to_numpy(), dtype=torch.float32).view(-1, 1)\n",
    "y_test_tensor_log = torch.tensor(y_test_log.to_numpy(), dtype=torch.float32).view(-1, 1)\n",
    "\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor_log)\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor_log)\n",
    "\n",
    "batch_size = 64\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size)"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/christianpisani/Learning/Posgrado/venv/lib/python3.12/site-packages/sklearn/preprocessing/_encoders.py:242: UserWarning: Found unknown categories in columns [3] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T03:32:19.677768Z",
     "start_time": "2024-10-18T03:32:19.666699Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model = UsedCarQuoteNN(X_train_processed.shape[1])\n",
    "\n",
    "criterion = torch.nn.L1Loss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-5)"
   ],
   "id": "d2e10b76d51ce9c2",
   "outputs": [],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T03:35:36.537755Z",
     "start_time": "2024-10-18T03:34:52.869814Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def train_model_batch(model, train_loader, X_val, y_val, epochs=100):\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        for X_batch, y_batch in train_loader:\n",
    "            y_pred_train = model(X_batch)\n",
    "            loss = criterion(y_pred_train, y_batch)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            y_pred_val = model(X_val)\n",
    "            mae = criterion(y_pred_val, y_val).item()\n",
    "\n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            # print(f'Epoch [{epoch+1}/{epochs}], Loss: {loss:.4f}, Val Loss: {mae.item():.4f}')\n",
    "            print(f'Epoch [{epoch+1}/{epochs}], Loss: {loss.item():.4f}, MAE: {mae:.4f}')\n",
    "\n",
    "\n",
    "train_model_batch(model, train_loader, X_test_tensor, y_test_tensor_log, epochs=1000)"
   ],
   "id": "926c4fae2f523a91",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/1000], Loss: 0.4027, MAE: 0.8940\n",
      "Epoch [20/1000], Loss: 0.4168, MAE: 0.7905\n",
      "Epoch [30/1000], Loss: 0.3811, MAE: 0.7700\n",
      "Epoch [40/1000], Loss: 0.4889, MAE: 1.0600\n",
      "Epoch [50/1000], Loss: 0.4116, MAE: 0.9899\n",
      "Epoch [60/1000], Loss: 0.4138, MAE: 0.7483\n",
      "Epoch [70/1000], Loss: 0.4413, MAE: 0.7005\n",
      "Epoch [80/1000], Loss: 0.6319, MAE: 0.5917\n",
      "Epoch [90/1000], Loss: 0.4556, MAE: 1.6547\n",
      "Epoch [100/1000], Loss: 0.6996, MAE: 0.7337\n",
      "Epoch [110/1000], Loss: 0.3588, MAE: 1.9598\n",
      "Epoch [120/1000], Loss: 0.6309, MAE: 0.5850\n",
      "Epoch [130/1000], Loss: 0.4181, MAE: 0.6972\n",
      "Epoch [140/1000], Loss: 0.5705, MAE: 1.1463\n",
      "Epoch [150/1000], Loss: 0.4473, MAE: 0.5674\n",
      "Epoch [160/1000], Loss: 0.5571, MAE: 1.4464\n",
      "Epoch [170/1000], Loss: 0.2996, MAE: 0.5784\n",
      "Epoch [180/1000], Loss: 0.4773, MAE: 0.6573\n",
      "Epoch [190/1000], Loss: 0.4529, MAE: 0.7618\n",
      "Epoch [200/1000], Loss: 0.3944, MAE: 2.4196\n",
      "Epoch [210/1000], Loss: 0.6088, MAE: 4.1434\n",
      "Epoch [220/1000], Loss: 0.5203, MAE: 0.5663\n",
      "Epoch [230/1000], Loss: 0.3527, MAE: 1.4769\n",
      "Epoch [240/1000], Loss: 0.3878, MAE: 0.5300\n",
      "Epoch [250/1000], Loss: 0.6146, MAE: 0.5770\n",
      "Epoch [260/1000], Loss: 0.3197, MAE: 0.6069\n",
      "Epoch [270/1000], Loss: 0.3919, MAE: 0.6625\n",
      "Epoch [280/1000], Loss: 0.4157, MAE: 1.3577\n",
      "Epoch [290/1000], Loss: 0.3024, MAE: 0.8461\n",
      "Epoch [300/1000], Loss: 0.2688, MAE: 0.7321\n",
      "Epoch [310/1000], Loss: 0.3100, MAE: 0.6130\n",
      "Epoch [320/1000], Loss: 0.3414, MAE: 0.7081\n",
      "Epoch [330/1000], Loss: 0.3943, MAE: 0.8247\n",
      "Epoch [340/1000], Loss: 0.4913, MAE: 1.1439\n",
      "Epoch [350/1000], Loss: 0.2972, MAE: 2.2919\n",
      "Epoch [360/1000], Loss: 0.3034, MAE: 0.5054\n",
      "Epoch [370/1000], Loss: 0.4722, MAE: 2.0012\n",
      "Epoch [380/1000], Loss: 0.5109, MAE: 0.4825\n",
      "Epoch [390/1000], Loss: 0.6442, MAE: 0.6076\n",
      "Epoch [400/1000], Loss: 0.6372, MAE: 1.1985\n",
      "Epoch [410/1000], Loss: 0.5246, MAE: 0.4930\n",
      "Epoch [420/1000], Loss: 0.4140, MAE: 0.4951\n",
      "Epoch [430/1000], Loss: 0.2852, MAE: 2.5283\n",
      "Epoch [440/1000], Loss: 0.3300, MAE: 0.5698\n",
      "Epoch [450/1000], Loss: 0.3620, MAE: 0.5377\n",
      "Epoch [460/1000], Loss: 0.4031, MAE: 0.8681\n",
      "Epoch [470/1000], Loss: 0.6354, MAE: 1.0597\n",
      "Epoch [480/1000], Loss: 0.9026, MAE: 0.7748\n",
      "Epoch [490/1000], Loss: 0.3944, MAE: 0.8548\n",
      "Epoch [500/1000], Loss: 0.5538, MAE: 0.7241\n",
      "Epoch [510/1000], Loss: 0.4259, MAE: 0.5372\n",
      "Epoch [520/1000], Loss: 0.4349, MAE: 0.5172\n",
      "Epoch [530/1000], Loss: 0.4056, MAE: 0.4227\n",
      "Epoch [540/1000], Loss: 0.2823, MAE: 1.6070\n",
      "Epoch [550/1000], Loss: 0.2799, MAE: 0.7920\n",
      "Epoch [560/1000], Loss: 0.2970, MAE: 0.4865\n",
      "Epoch [570/1000], Loss: 0.3036, MAE: 0.6020\n",
      "Epoch [580/1000], Loss: 0.4359, MAE: 1.3182\n",
      "Epoch [590/1000], Loss: 0.3213, MAE: 2.2141\n",
      "Epoch [600/1000], Loss: 0.2634, MAE: 0.8301\n",
      "Epoch [610/1000], Loss: 0.3479, MAE: 1.1738\n",
      "Epoch [620/1000], Loss: 0.4298, MAE: 1.5341\n",
      "Epoch [630/1000], Loss: 0.3111, MAE: 0.4817\n",
      "Epoch [640/1000], Loss: 0.2423, MAE: 1.9639\n",
      "Epoch [650/1000], Loss: 0.3562, MAE: 1.0971\n",
      "Epoch [660/1000], Loss: 0.2459, MAE: 0.6574\n",
      "Epoch [670/1000], Loss: 0.2915, MAE: 0.5743\n",
      "Epoch [680/1000], Loss: 0.2156, MAE: 0.5209\n",
      "Epoch [690/1000], Loss: 0.3662, MAE: 0.5440\n",
      "Epoch [700/1000], Loss: 0.6620, MAE: 0.9334\n",
      "Epoch [710/1000], Loss: 0.3542, MAE: 0.9736\n",
      "Epoch [720/1000], Loss: 0.3028, MAE: 0.5040\n",
      "Epoch [730/1000], Loss: 0.2850, MAE: 0.3951\n",
      "Epoch [740/1000], Loss: 0.2417, MAE: 0.5297\n",
      "Epoch [750/1000], Loss: 0.2867, MAE: 0.4368\n",
      "Epoch [760/1000], Loss: 0.2949, MAE: 1.4024\n",
      "Epoch [770/1000], Loss: 0.2073, MAE: 0.4216\n",
      "Epoch [780/1000], Loss: 0.2670, MAE: 0.5970\n",
      "Epoch [790/1000], Loss: 0.2450, MAE: 0.3929\n",
      "Epoch [800/1000], Loss: 0.2920, MAE: 1.1924\n",
      "Epoch [810/1000], Loss: 0.2206, MAE: 0.7423\n",
      "Epoch [820/1000], Loss: 0.3103, MAE: 0.7567\n",
      "Epoch [830/1000], Loss: 0.2346, MAE: 1.4877\n",
      "Epoch [840/1000], Loss: 0.2405, MAE: 0.6785\n",
      "Epoch [850/1000], Loss: 0.2663, MAE: 0.5222\n",
      "Epoch [860/1000], Loss: 0.3376, MAE: 0.4553\n",
      "Epoch [870/1000], Loss: 0.5094, MAE: 0.6197\n",
      "Epoch [880/1000], Loss: 0.2139, MAE: 0.6629\n",
      "Epoch [890/1000], Loss: 0.3001, MAE: 0.4966\n",
      "Epoch [900/1000], Loss: 0.2548, MAE: 0.4108\n",
      "Epoch [910/1000], Loss: 0.2678, MAE: 0.4232\n",
      "Epoch [920/1000], Loss: 0.2984, MAE: 0.5706\n",
      "Epoch [930/1000], Loss: 0.2266, MAE: 2.4439\n",
      "Epoch [940/1000], Loss: 0.2825, MAE: 0.3899\n",
      "Epoch [950/1000], Loss: 0.2140, MAE: 1.1316\n",
      "Epoch [960/1000], Loss: 0.3301, MAE: 0.7270\n",
      "Epoch [970/1000], Loss: 0.2890, MAE: 1.2223\n",
      "Epoch [980/1000], Loss: 0.2549, MAE: 1.0803\n",
      "Epoch [990/1000], Loss: 0.2495, MAE: 0.5095\n",
      "Epoch [1000/1000], Loss: 0.2042, MAE: 0.4799\n"
     ]
    }
   ],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T03:45:57.740962Z",
     "start_time": "2024-10-18T03:45:57.647591Z"
    }
   },
   "cell_type": "code",
   "source": [
    "y_pred_ridge_log = model(X_test_tensor)\n",
    "y_pred_ridge = np.expm1(y_pred_ridge_log.detach().numpy())\n",
    "\n",
    "metrics_ridge = {\n",
    "    \"name\": \"NN\",\n",
    "    \"MAE_training\": mean_absolute_error(y_train_log, model(X_test_tensor).detach().numpy()),\n",
    "    \"MAE\": mean_absolute_error(y_test, y_pred_ridge),\n",
    "    \"RMSE\": root_mean_squared_error(y_test, y_pred_ridge),\n",
    "    \"MAPE\": mean_absolute_percentage_error(y_test, y_pred_ridge),\n",
    "    \"R2\": r2_score(y_test, y_pred_ridge)\n",
    "}"
   ],
   "id": "d0630e62998854ef",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ld/xrn98pq139jc2vr4hz8vsxr00000gn/T/ipykernel_20491/912258933.py:2: RuntimeWarning: overflow encountered in expm1\n",
      "  y_pred_ridge = np.expm1(y_pred_ridge_log.detach().numpy())\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [5689, 2439]",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[38], line 6\u001B[0m\n\u001B[1;32m      1\u001B[0m y_pred_ridge_log \u001B[38;5;241m=\u001B[39m model(X_test_tensor)\n\u001B[1;32m      2\u001B[0m y_pred_ridge \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mexpm1(y_pred_ridge_log\u001B[38;5;241m.\u001B[39mdetach()\u001B[38;5;241m.\u001B[39mnumpy())\n\u001B[1;32m      4\u001B[0m metrics_ridge \u001B[38;5;241m=\u001B[39m {\n\u001B[1;32m      5\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mname\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mRidge\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m----> 6\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mMAE_training\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[43mmean_absolute_error\u001B[49m\u001B[43m(\u001B[49m\u001B[43my_train_log\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX_test_tensor\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdetach\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnumpy\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m,\n\u001B[1;32m      7\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mMAE\u001B[39m\u001B[38;5;124m\"\u001B[39m: mean_absolute_error(y_test, y_pred_ridge),\n\u001B[1;32m      8\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mRMSE\u001B[39m\u001B[38;5;124m\"\u001B[39m: root_mean_squared_error(y_test, y_pred_ridge),\n\u001B[1;32m      9\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mMAPE\u001B[39m\u001B[38;5;124m\"\u001B[39m: mean_absolute_percentage_error(y_test, y_pred_ridge),\n\u001B[1;32m     10\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mR2\u001B[39m\u001B[38;5;124m\"\u001B[39m: r2_score(y_test, y_pred_ridge)\n\u001B[1;32m     11\u001B[0m }\n",
      "File \u001B[0;32m~/Learning/Posgrado/venv/lib/python3.12/site-packages/sklearn/utils/_param_validation.py:213\u001B[0m, in \u001B[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    207\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m    208\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m config_context(\n\u001B[1;32m    209\u001B[0m         skip_parameter_validation\u001B[38;5;241m=\u001B[39m(\n\u001B[1;32m    210\u001B[0m             prefer_skip_nested_validation \u001B[38;5;129;01mor\u001B[39;00m global_skip_validation\n\u001B[1;32m    211\u001B[0m         )\n\u001B[1;32m    212\u001B[0m     ):\n\u001B[0;32m--> 213\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    214\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m InvalidParameterError \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m    215\u001B[0m     \u001B[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001B[39;00m\n\u001B[1;32m    216\u001B[0m     \u001B[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001B[39;00m\n\u001B[1;32m    217\u001B[0m     \u001B[38;5;66;03m# the name of the estimator by the name of the function in the error\u001B[39;00m\n\u001B[1;32m    218\u001B[0m     \u001B[38;5;66;03m# message to avoid confusion.\u001B[39;00m\n\u001B[1;32m    219\u001B[0m     msg \u001B[38;5;241m=\u001B[39m re\u001B[38;5;241m.\u001B[39msub(\n\u001B[1;32m    220\u001B[0m         \u001B[38;5;124mr\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mparameter of \u001B[39m\u001B[38;5;124m\\\u001B[39m\u001B[38;5;124mw+ must be\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m    221\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mparameter of \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mfunc\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__qualname__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m must be\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m    222\u001B[0m         \u001B[38;5;28mstr\u001B[39m(e),\n\u001B[1;32m    223\u001B[0m     )\n",
      "File \u001B[0;32m~/Learning/Posgrado/venv/lib/python3.12/site-packages/sklearn/metrics/_regression.py:216\u001B[0m, in \u001B[0;36mmean_absolute_error\u001B[0;34m(y_true, y_pred, sample_weight, multioutput)\u001B[0m\n\u001B[1;32m    152\u001B[0m \u001B[38;5;129m@validate_params\u001B[39m(\n\u001B[1;32m    153\u001B[0m     {\n\u001B[1;32m    154\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124my_true\u001B[39m\u001B[38;5;124m\"\u001B[39m: [\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124marray-like\u001B[39m\u001B[38;5;124m\"\u001B[39m],\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    162\u001B[0m     y_true, y_pred, \u001B[38;5;241m*\u001B[39m, sample_weight\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, multioutput\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124muniform_average\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    163\u001B[0m ):\n\u001B[1;32m    164\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Mean absolute error regression loss.\u001B[39;00m\n\u001B[1;32m    165\u001B[0m \n\u001B[1;32m    166\u001B[0m \u001B[38;5;124;03m    Read more in the :ref:`User Guide <mean_absolute_error>`.\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    214\u001B[0m \u001B[38;5;124;03m    0.85...\u001B[39;00m\n\u001B[1;32m    215\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m--> 216\u001B[0m     y_type, y_true, y_pred, multioutput \u001B[38;5;241m=\u001B[39m \u001B[43m_check_reg_targets\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    217\u001B[0m \u001B[43m        \u001B[49m\u001B[43my_true\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_pred\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmultioutput\u001B[49m\n\u001B[1;32m    218\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    219\u001B[0m     check_consistent_length(y_true, y_pred, sample_weight)\n\u001B[1;32m    220\u001B[0m     output_errors \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39maverage(np\u001B[38;5;241m.\u001B[39mabs(y_pred \u001B[38;5;241m-\u001B[39m y_true), weights\u001B[38;5;241m=\u001B[39msample_weight, axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m)\n",
      "File \u001B[0;32m~/Learning/Posgrado/venv/lib/python3.12/site-packages/sklearn/metrics/_regression.py:111\u001B[0m, in \u001B[0;36m_check_reg_targets\u001B[0;34m(y_true, y_pred, multioutput, dtype, xp)\u001B[0m\n\u001B[1;32m     76\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Check that y_true and y_pred belong to the same regression task.\u001B[39;00m\n\u001B[1;32m     77\u001B[0m \n\u001B[1;32m     78\u001B[0m \u001B[38;5;124;03mParameters\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    107\u001B[0m \u001B[38;5;124;03m    correct keyword.\u001B[39;00m\n\u001B[1;32m    108\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    109\u001B[0m xp, _ \u001B[38;5;241m=\u001B[39m get_namespace(y_true, y_pred, multioutput, xp\u001B[38;5;241m=\u001B[39mxp)\n\u001B[0;32m--> 111\u001B[0m \u001B[43mcheck_consistent_length\u001B[49m\u001B[43m(\u001B[49m\u001B[43my_true\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_pred\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    112\u001B[0m y_true \u001B[38;5;241m=\u001B[39m check_array(y_true, ensure_2d\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m, dtype\u001B[38;5;241m=\u001B[39mdtype)\n\u001B[1;32m    113\u001B[0m y_pred \u001B[38;5;241m=\u001B[39m check_array(y_pred, ensure_2d\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m, dtype\u001B[38;5;241m=\u001B[39mdtype)\n",
      "File \u001B[0;32m~/Learning/Posgrado/venv/lib/python3.12/site-packages/sklearn/utils/validation.py:457\u001B[0m, in \u001B[0;36mcheck_consistent_length\u001B[0;34m(*arrays)\u001B[0m\n\u001B[1;32m    455\u001B[0m uniques \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39munique(lengths)\n\u001B[1;32m    456\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(uniques) \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[0;32m--> 457\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m    458\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mFound input variables with inconsistent numbers of samples: \u001B[39m\u001B[38;5;132;01m%r\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    459\u001B[0m         \u001B[38;5;241m%\u001B[39m [\u001B[38;5;28mint\u001B[39m(l) \u001B[38;5;28;01mfor\u001B[39;00m l \u001B[38;5;129;01min\u001B[39;00m lengths]\n\u001B[1;32m    460\u001B[0m     )\n",
      "\u001B[0;31mValueError\u001B[0m: Found input variables with inconsistent numbers of samples: [5689, 2439]"
     ]
    }
   ],
   "execution_count": 38
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "f3c075f577a8edba"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
